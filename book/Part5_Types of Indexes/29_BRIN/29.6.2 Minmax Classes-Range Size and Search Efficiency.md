정확한 범위 크기는 특정 값을 저장할 때 사용되는 페이지 수를 기준으로 결정할 수 있다.

*scheduled_time* 열을 살펴보고, 특정 24시간 내에 수행된 항공편에 정보를 알아보자.  먼저 이 시간 간격에 해당하는 데이터가 몇 개의 테이블 페이지에 걸쳐 있는지 확인해야 한다.

이 숫자를 얻기 위해, TID가 페이지 번호와 오프셋으로 구성되는 걸 활용할 수 있다. 불행히도, TID를 이 두 구성 요소로 분해하는 내장 함수는 없기 때문에, 텍스트 포현을 통한 타입 캐스팅을 사용하여 다소 번거로운 함수를 작성해야 한다 :

```sql
=> CREATE FUNCTION tid2page(t tid) RETURNS integer
   LANGUAGE sql
   RETURN (t::text::point)[0]::integer;
```

이제 테이블에 날짜가 어떻게 분포되어 있는지 알 수 있다.


```sql
=> SELECT min(numblk), round(avg(numblk)) avg, max(numblk)
   FROM (
       SELECT count(distinct tid2page(ctid)) numblk
       FROM flights_bi
       GROUP BY scheduled_time::date
   ) t;

min  | avg  | max
------+-------+------
1192 | 1447  | 1512
(1 row)
```

알아차렸듯이, 데이터 분포는 균일하지 않다. 표준 범위 크기인 128페이지를 사용할 경우, 각 날짜는 9~12의 범위를 차지할 것이다. 
특정 날짜의 데이터를 가져올 때, 인덱스 스캔은 필요한 행 뿐만 아니라 같은 범위에 속해 있는 다른 날짜의 행도 반환할 것이다.
범위 크기가 커질수록, 불필요하게 읽히는 경계갑이 많아지며, 범위 크기를 조정해 이 수를 조정할 수 있다.

특정 날짜에 대한 쿼리를 시도해 보자(이미 인덱스를 기본 세팅으로 만들었다). 간결함을 위해, 병렬 실행은 금지한다 :

```sql
=> SET max_parallel_workers_per_gather = 0;
=> \set d '2016-08-15 02:45:00+03'
=> EXPLAIN (analyze, buffers, costs off, timing off, summary off)
   SELECT *
   FROM flights_bi
   WHERE scheduled_time >= :'d'::timestamptz
     AND scheduled_time < :'d'::timestamptz + interval '1 day';

QUERY PLAN
-----------------------------------------------------------------------------
Bitmap Heap Scan on flights_bi (actual rows=81964 loops=1)
  Recheck Cond: ((scheduled_time >= '2016-08-15 02:45:00+03'::timestamptz) ...
  Rows Removed by Index Recheck: 11606
  Heap Blocks: lossy=1536
  Buffers: shared hit=1561
  -> Bitmap Index Scan on flights_bi_scheduled_time_idx
     (actual rows=15360 loops=1)
     Index Cond: ((scheduled_time >= '2016-08-15 02:45:00+03'::timestamptz ...
     Buffers: shared hit=25
Planning:
	Buffers: shared hit=1
(11 rows)
```

특정 쿼리에 대해 BRIN의 효율성을 인덱스 스캔에서 건너뛴 페이지 수와 테이블의 총 페이지 수의 비율로 정의할 수 있다.
만약 효율성 계수가 0이라면, 인덱스 접근은 순차 스캔과 동일해지며(추가 비용을 제외하고), 효율성 계수가 높아질수록, 읽어야 할 페이지 수가 줄어든다.
그러나 일부 페이지에는 반환할 데이터가 포함되어 있어 건너뛸 수 없기 때문에, 효율성 계수는 항상 1보다 작다.

이 경우에, 효율성 계수는   $\frac{528417 - 1561}{528417} \approx 0.997$ 이며, 528,417개가 테이블의 총 페이지이다.

그러나, 단일 값만으로는 의미 있는 결론을 내릴 수 없다.
데이터가 균일하고 이상적이라고 하더라도, 경계 범위와 페이지 경계가 일치하지 않기 때문에 효율성은 여전히 변동할 것이다.
효율성 계수를 랜덤 값으로 간주하고 그 분포를 해석해야만 전체적인 그림을 얻을 수 있다.

이 예시에서, 연중 모든 날짜를 선택하고, 각 날짜에 대한 실행 계획을 확인한 뒤, 이를 기반으로 통계를 계산할 수 있다.
이 과정은 `EXPLAIN` 명령이 JSON 형식으로 반환할 수 있어 쉽게 자동화하고 파싱하기 편리하다.
전체 코드를 제공하지는 않지만, 다음 코드 조각에 중요한 세부 사항이 포함되어 있다 :

```sql
=> DO $$
DECLARE
    plan jsonb;
BEGIN
    EXECUTE
        'EXPLAIN (analyze, buffers, timing off, costs off, format json)
         SELECT * FROM flights_bi
         WHERE scheduled_time >= $1
           AND scheduled_time < $1 + interval ''1 day'''
    USING '2016-08-15 02:45:00+03'::timestamptz
    INTO plan;

    RAISE NOTICE 'shared hit=%, read=%',
        plan -> 0 -> 'Plan' ->> 'Shared Hit Blocks',
        plan -> 0 -> 'Plan' ->> 'Shared Read Blocks';
END;
$$;

NOTICE: shared hit=1561, read=0
DO
```

결과는 box plot으로 시각화할 수 있으며, "box-and-whiskers"로도 알려져 있다.
여기서 whiskers는 첫번째, 4번째 사분위수를 나타낸다(오른쪽 위스커는 가장 큰 값 중 25%, 왼쪽은 가장 작은 25%).
상자 자체는 나머지50%의 값을 포함하며, 중앙값이 표시된다.
중요한 점은, 이 간결한 표현이 다양한 결과를 시각적으로 비교할 수 있게 해준다는 것이다. 다음 그림은 기본 범위 크기, 기본 크기보다 4배 큰, 4배 작은 크기에 대한 효율성 계수 분포를 보여준다.

예상할 수 있듯, 검색 정확도와 효율성은 상당히 큰 범위에서도 높게 유지된다.

점선은 여기서 쿼리에 대한 가능한 최대 효율성 계수의 평균 값을 나타내며, 하루가 테이블의 약 $\frac{1}{365}$를 차지한다고 가정한 값이다.

![](image/CleanShot%20-000130.png)

