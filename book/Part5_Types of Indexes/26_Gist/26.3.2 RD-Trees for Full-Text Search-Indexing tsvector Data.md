
빠르게 작동하기 위해, 전체 텍스트 검색은 인덱스의 지원을 받아야 한다.[^1] 문서 자체가 아니라 *tsvector* 값이 인덱싱되므로, 두 가지 선택지가 있다 :
표현식에 대한 인덱스를 생성하고 타입 캐스트를 수행하거나, *tsvector* 타입의 별도 컬럼을 추가하고 인덱스를 생성하는 것이다.
첫 번째 방법의 장점은 *tsvector* 값을 저장할 공간을 낭비하지 않는다는 점이다. 이 값은 실제로 필요하지 않기 때문이다. 하지만 두번째보단 느린데, 접근 방법에 의해 반환된 모든 힙 튜플을 인덱싱 엔진이 다시 확인해야 하기 때문이다.
이는 *tsvector* 값을 다시 확인되는 각 행마다 다시 계산해야 함을 의미하며, 곧 보겠지만 Gist는 모든 행을 다시 확인한다.

간단한 예제를 만들어 보자. 
두 컬럼의 테이블을 생성하자 : 첫 컬럼은 문서를 저장하고, 두번째 컬럼은 *tsvector* 값을 저장한다. 두 번째 컬럼을 갱신하기 위해 트리거를 사용할 수 있지만, 이 컬럼을 단순히 생성된 컬럼으로 전환하는 것이 더 편리하다.

```sql
=> CREATE TABLE ts(
   doc text,
   doc_tsv tsvector GENERATED ALWAYS AS (
      to_tsvector('pg_catalog.english', doc)
   ) STORED
);

=> CREATE INDEX ts_gist_idx ON ts
   USING gist(doc_tsv);
```

> 이 예제에서는 *to_tsvector* 함수를 단일 인수로 사용했으며, *default_text_search_config* 매개변수를 통해 전체 텍스트 검색 구성을 정의했다.
> 이 함수 버전의 변동성 범주는 해당 매개변수에 암묵적으로 의존하기 때문에 "STABLE"이다.
> 하지만 여기에서는 구성을 명시적으로 정의하는 또 다른 버전을 사용하며, 이 버전은 "immutable"이고 생성 표현식에서 사용할 수 있다.

여러 행 삽입 :

```sql
=> INSERT INTO ts(doc)
   VALUES
   ('Old MacDonald had a farm'),
   ('And on his farm he had some cows'),
   ('Here a moo, there a moo'),
   ('Everywhere a moo moo'),
   ('Old MacDonald had a farm'),
   ('And on his farm he had some chicks'),
   ('Here a cluck, there a cluck'),
   ('Everywhere a cluck cluck'),
   ('Old MacDonald had a farm'),
   ('And on his farm he had some pigs'),
   ('Here an oink, there an oink'),
   ('Everywhere an oink oink')
   RETURNING doc_tsv;

doc_tsv
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
'farm':5 'macdonald':2 'old':1
'cow':8 'farm':4
'moo':3,6
'everywher':1 'moo':3,4
'farm':5 'macdonald':2 'old':1
'chick':8 'farm':4
'cluck':3,6
'cluck':3,4 'everywher':1
'farm':5 'macdonald':2 'old':1
'farm':4 'pig':8
'oink':3,6
'everywher':1 'oink':3,4
(12 rows)
INSERT 0 12
```

따라서, R-tree는 인덱싱에 적합하지 않은데, 문서에는 경계 상자 개념이 적용되지 않기 때문이다. 그러므로, RD-tree(러시안 인형 구조)변형이 유용하다.
이는 경계 상자 대신 경계 집합을 사용하는데, 경계 집합은 하위 요소의 모든 집합을 포함한다.
전체 텍스트 검색의 경우, 이러한 집합은 문서의 lexemes를 포함하지만, 일반적으로 경계 집합은 임의의 요소를 포함할 수 있다.


인덱스 항목에서 경계 집합을 포함하는 방법에는 여러 가지가 있다. 가장 간단한 방법은 집합의 모든 요소를 열거하는 것이다.
다음은 그 예시이다 :


![](_static/Pasted%20image%2020241028155257.png)

`DOC_TSV @@ TO_TSQUERY('cow')` 조건을 만족하는 문서를 찾기 위해, 자식 항목에 "cow" lexme가 포함되어 있는 것으로 알려진 노드로 내려가야 한다.

이러한 표현 방식의 문제는 명확하다. 문서 내 lexmes의 수는 방대할 수 있는 반면, 페이지 수는 제한되어 있다.
특정 문서가 갖는 고유 lexmes의 수는 많지 않더라도, 트리의 상위 레벨에서 이들을 모두 합친 집합은 여전히 너무 크다.

![](_static/Pasted%20image%2020241028161539.png)

전체 텍스트 검색은 또 다른 해결책, 즉 더 압축된 *signature tree*를 사용한다. 이는 Bloom Filter를 다뤄 본 사람에게는 익숙할 것이다.

각 lexeme는 하나의 서명으로 표현될 수 있다 : 서명은 특정 길이의 문자열이며, 이 문자열에서  하나의 비트만 1로 설정된다. 설정할 비트는 lexme의 해시 함수에 의해 결정된다.

문서의 서명은 해당 문서 내 모든 lexeme의 서명에 대해 비트 단위 OR 연산을 수행한다.

각 lexemes에 다음과 같은 서명이  할당되었다고 가정해 보자 :

- `chick`: 1000000
- `cluck`: 0001000
- `cow`: 0000010
- `everywhere`: 0010000
- `farm`: 0000100
- `macdonald`: 0100000
- `moo`: 0000100
- `oink`: 0000010
- `old`: 0000001
- `pig`: 0010000

그러면 문서의 서명은 다음과 같다 :

- `"Old MacDonald had a farm"`: `0100101`
- `"And on his farm he had some cows"`: `0000110`
- `"Here a moo, there a moo"`: `0000100`
- `"Everywhere a moo moo"`: `0010100`
- `"And on his farm he had some chicks"`: `1000100`
- `"Here a cluck, there a cluck"`: `0001000`
- `"Everywhere a cluck cluck"`: `0011000`
- `"And on his farm he had some pigs"`: `0010100`
- `"Here an oink, there an oink"`: `0000010`
- `"Everywhere an oink oink"`: `0010010`

그리고 인덱스 트리는 다음과 같이 표현된다 :

![](_static/Pasted%20image%2020241028161927.png)

이 방식의 장점은 분명하다 : 인덱스 항목이 작고 크기가 동일하기 때문에 인덱스가 상당히 컴팩트하다.
하지만 몇 단점도 존재한다. 
우선, 인덱스가 더 이상 인덱스 키를 저장하지 않기 때문에 index-only scan을 사용할 수 없고, 반환된 각 튜플을 테이블에서 다시 확인해야 한다.
또한 정확도도 저하된다 : 인덱스가 많은 거짓 긍정을 반활할 수 있으며, 이들은 재확인 과정에서 걸러져야 한다.

`DOC_TSV @@ TO_TSQUERY('cos')` 조건을 다시 살펴보자. 쿼리의 서명은 문서의 서명과 동일한 방식으로 계산되며, 이 경우 서명은 `0000010`이다. 일관성 함수[^2]는 서명에 동일한 비트가 설정된 모든 자식 노드를 찾아야 한다 :

![](_static/Pasted%20image%2020241028162408.png)

이전 예제와 비교할 때, 거짓 긍정으로 인해 더 많은 노드를 스캔해야 한다. 서명의 용량이 제한되어 있으므로, 큰 lexeme 집합에서는 일부가 동일한 서명을 가질 수밖에 없다. 이 예제에서는 "cow", "oink"이다.
이는 동일한 서명이 서로 다른 여러 문서와 일치할 수 있으며, 이 경우 쿼리의 서명이 3개와 일치한다.

거짓 긍정은 인덱스의 효율성을 감소시키지만, 정확성에는 영향이 없다 : 거짓 부정은 확실히 배제되기 때문에, 필요한 값이 누락되는 경우는 없다.

서명의 크기는 실제로 더 크다. 디폴트로 124바이트(992b)를 사용하므로, 이 예제보다 충돌 확률이 훨씬 낮다. 필요하다면, 연산자 클래스 매개변수를 사용해 서명 크기를 2000바이트까지 늘릴 수 있다 :

```sql
CREATE INDEX ... USING gist(column tsvector_ops(siglen = size));
```

또한 값이 충분히 작다면(표준 페이지의 $\frac{1}{16}$보다 작은 경우로 500bytes 정도), [^3] *tsvector_ops* 연산자 클래스는 인덱스에 리프 페이지의 서명이 아니라 *tsvector* 값 자체를 저장한다.

실제 데이터에서 인덱싱이 어떻게 작동하는지 확인하기 위해 *pgsql-hackers* 메일링 리스트 아카이브를 사용할 수 있다. [^4] 이 아카이브에는 356,125개의 이메일이 있으며, 각각의 전송 날짜, 제목, 작성자 이름, 본문 텍스트가 포함되어 있다.

*txvector* 타입의 컬럼을 추가하고 인덱스를 생성해 보자. 여기서는 세 가지 값(subject, author, body text)를 하나의 벡터로 결합하여 문서가 동적으로 생성될 수 있으며 반드시 하나의 컬럼에 저장될 필요가 없다는 점을 보여준다.

```sql
=> ALTER TABLE mail_messages ADD COLUMN tsv tsvector
   GENERATED ALWAYS AS (to_tsvector(
      'pg_catalog.english', subject || ' ' || author || ' ' || body_plain
   )) STORED;

NOTICE:
word is too long to be indexed
DETAIL:
Words longer than 2047 characters are ignored.
...
NOTICE:
word is too long to be indexed
DETAIL:
Words longer than 2047 characters are ignored.
ALTER TABLE

=> CREATE INDEX mail_gist_idx ON mail_messages USING gist(tsv);

=> SELECT pg_size_pretty(pg_relation_size('mail_gist_idx'));

pg_size_pretty
−−−−−−−−−−−−−−−−
127 MB
(1 row)
```

컬럼이 채워지는 동안, 크기가 큰 일부 단어는 필터링됬다. 그러나 인덱스가 준비되면, 검색 쿼리에 사용할 수 있다.

```sql
=> EXPLAIN (analyze, costs off, timing off, summary off)
   SELECT *
   FROM mail_messages
   WHERE tsv @@ to_tsquery('magic & value');

QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Index Scan using mail_gist_idx on mail_messages
(actual rows=898 loops=1)
Index Cond: (tsv @@ to_tsquery('magic & value'::text))
Rows Removed by Index Recheck: 7859
(4 rows)
```


인덱스가 반환한 행 중에서 7859개는 재확인 과정에서 제거되었으며, 898개의 행이 실제로 조건을 만족했다.
서명의 크기를 늘리면 정확도(그리고 결과적으로, 인덱스 효율성)가 증가하지만, 인덱스 크기도 커진다.

```sql
=> DROP INDEX mail_messages_tsv_idx;


=> CREATE INDEX ON mail_messages
   USING gist(tsv tsvector_ops(siglen=248));


=> SELECT pg_size_pretty(pg_relation_size('mail_messages_tsv_idx'));

pg_size_pretty
−−−−−−−−−−−−−−−−
139 MB
(1 row)



=> EXPLAIN (analyze, costs off, timing off, summary off)
   SELECT *
   FROM mail_messages
   WHERE tsv @@ to_tsquery('magic & value');

QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Index Scan using mail_messages_tsv_idx on mail_messages
(actual rows=898 loops=1)
Index Cond: (tsv @@ to_tsquery('magic & value'::text))
Rows Removed by Index Recheck: 2060
(4 rows)

```




[^1]:https://www.postgresql.org/docs/14/textsearch-indexes.html
[^2]:[backend/utils/adt/tsgistidx.c, gtsvector_consistent function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/utils/adt/tsgistidx.c;hb=REL_14_STABLE)
[^3]:[backend/utils/adt/tsgistidx.c, gtsvector_compress function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/utils/adt/tsgistidx.c;hb=REL_14_STABLE)
[^4]:[다운로드링크]( https://edu.postgrespro.ru/mail_messages.sql.gz)