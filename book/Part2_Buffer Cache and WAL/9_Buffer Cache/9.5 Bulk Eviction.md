bulk 읽기나 쓰기 작업이 수행될 때, 일회성 데이터가 유용한 페이지들을 버퍼 캐시에서 빠르게 밀어낼 수 있다.

이를 예방하기 위해, bulk 작업은 상대적으로 작은 *buffer rings*를 사용하며, 축출은 그 경계 내에서만 사용되어 다른 버퍼에 영향을 미치지 않는다.

>"buffer ring"과 함께 코드에서는 "ring buffer" 라는 용어도 사용된다. 그러나, 이 용어는 다소 모호한데, ring buffer 자체로 여러 버퍼들(ㅓ퍼 캐시에 속하는)로 구성되어 있기 때문이다. "buffer ring" 이라는 용어가 더 정확하다.

특정 크기의 버퍼 링은 버퍼 배열로 구성되어 있으며, 이 버퍼 링은 차례로 사용된다. 
처음에는, 버퍼 링은 비어 있고, 개별 버퍼들이 하나씩 선택되어 하나씩 버퍼 링에 추가된다. 이후 버퍼 교체(eviction)이 발생하지만, 이는 오직 버퍼 링 안에서만 이루어진다. [^1]

ring에 추가된 버퍼들은 버퍼 캐시에서 제외되지 않으며, 여전히 다른 작업에서 사용할 수 있다. 따라서 재사용하려는 버퍼가 pinned 상태이거나 usage count가 1보다 높으면, 해당 버퍼는 단순히 링에서 분리되고 다른 버퍼로 대체된다.

PostgreSQL은 3가지 eviction 전략을 지원한다.

- **Bulk read strategy** 는 대량의 테이블을 순차적으로 스캔할 때 사용되며, 테이블 크기가 버퍼 캐시의 $\frac{1}{4}$ 초과하는 경우에 적용된다. ring buffer는 256kb(표준 페이지 32개)이다.
이 전략은 버퍼를 비우기 위해 더티 페이지를 디스크에 쓰는 것을 허용하지 않고, 대신 버퍼가 링에서 제외되고 다른 버퍼로 교체된다. 그 결과, 읽기 작업은 쓰기가 완료될 때까지 기다릴 필요가 없어 더 빠르게 수행된다.
만약 테이블이 이미 스캔되고 있는 상태라면, 또 다른 스캔을 시작한 프로세스는 기존에 버퍼 링에 합류하여 현재 사용 가능한 데이터를 접근하며, 추가적인 I/O를 발생시키지 않는다. 첫 프로세스가 스캔을 끝내면, 두번째 프로세스는 건너뛰었던 테이블 부분을 다시 스캔하게 된다. 
<br>

- **Bulk writes strategy** 는 `COPY FROM`, `CREATE TABLE AS SELECT`, `CREATE MATERIALIZED VIEW` , 그리고 테이블을 다시 쓰게 되는 `ALTER TABLE` 등의 명령들에 적용된다. 할당된 버퍼 링은 상당히 크며, 기본 크기는 16MB(기본 페이지 2048개)이다. 하지만 그 크기는 절대 버퍼 캐시의 $\frac{1}{8}$을 초과하지 않는다. '
<br>

- **Vacuuming strategy**는 vacuuming이 가시성 맵을 고려하지 않고 전체 테이블을 스캔할 때 사용된다. 이때 ring buffer는 256MB(32개의 표준 페이지)가 사용된다.


Buffer ring이 항상 원치 않는 eviction을 막지는 못한다. 만약   `UPDATE`나 `DELETE` 명령어가 많은 행에 영향을 미치면, 수행된 테이블 스캔은 대량 읽기 작업을 적용하지만, 페이지가 지속적으로 수정되기 때문에 버퍼 링이 사실상 무용지물이 된다.

또 다른 예시는 TOAST 테이블에 초과된 데이터를 저장하는 경우이다. 읽어야 할 데이터의 양이 많을 수 있음에도 불구하고, TOAST된 값들은 항상 인덱스를 통해 접근하기 때문에, 버퍼 링을 우회하게 된다.

*bulk read* 전략을 좀더 자세히 살펴보자. 간단하게, 삽입된 행이 페이지를 전부 차지하도록 테이블을 생성할 것이다. 디폴트로 버퍼 캐시는 16,384페이지이며, 각 8KB이다. 따라서, 테이블이 4096 페이지 이상을 차지해야 스캔이 버퍼 링을 사용할 수 있다.

```sql
=> CREATE TABLE big(
id integer PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
s char(1000)
) WITH (fillfactor = 10);


=> INSERT INTO big(s)
   SELECT 'FOO' FROM generate_series(1, 4096+1);
```
 테이블을 분석하자
```sql
=> ANALYZE big;  -- 통계정보를 갱신하여 테이블에 대한 최신 정보 알 수 있게함

=> SELECT relname, relfilenode, relpages
   FROM pg_class
   WHERE relname IN ('big', 'big_pkey');

relname  | relfilenode | relpages
---------+-------------+---------
big      | 16546       | 4097
big_pkey | 16551       | 14
(2 rows)
```

서버를 재시작하여 캐시를 지우자. 현제 캐시에는 분석 중에 읽힌 일부 힙 페이지가 들어있다.

```bash
postgres$ pg_ctl restart -l /home/postgres/logfile
```

서버가 시작되면, 테이블 전체를 읽어보자 : 

```sql
=> EXPLAIN (analyze, costs off, timing off, summary off)
   SELECT id FROM big;

QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Seq Scan on big (actual rows=4097 loops=1)
(1 row)
```

힙 페이지는 이 작업을 위해 32개의 버퍼만 차지하며, 이것이 작업을 위한 버퍼 링을 구성한다:


```sql
=> SELECT count(*)
	FROM pg_buffercache
	WHERE relfilenode = pg_relation_filenode('big'::regclass);
	
count
−−−−−−−
32
(1 row)
```

그러나 인덱스 스캔의 경우에 버퍼링은 사용되지 않는다:

```sql
=> EXPLAIN (analyze, costs off, timing off, summary off)
   SELECT * FROM big ORDER BY id;

QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Index Scan using big_pkey on big (actual rows=4097 loops=1)
(1 row)
```

결과적으로, 버퍼 캐시에는 전체 테이블과 전체 인덱스가 저장된다:
```sql
=> SELECT relfilenode, count(*)
   FROM pg_buffercache
   WHERE relfilenode IN (
      pg_relation_filenode('big'),
      pg_relation_filenode('big_pkey')
   )
   GROUP BY relfilenode;

relfilenode | count
------------+-------
     16546  | 4097
     16551  | 14
(2 rows)
```



[^1]:backend/storage/buffer/freelist.c, GetBufferFromRing function