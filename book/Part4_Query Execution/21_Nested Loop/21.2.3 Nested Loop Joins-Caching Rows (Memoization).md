만약 내부 집합이 동일한 매개변수 값으로 반복적으로 스캔된다면(같은 결과 반환), 내부 집합의 행을 캐싱하는 것이 유리할 수 있다.

이러한 캐싱은 *Memoize* 노드에 의해 수행된다. *Materialize*노드와 비슷한 역활을 하지만, *parameterized joins*를 수행하기 위해 설계된 보다 복잡한 구현을 가지고 있다 :

- *Materialize* 노드는 자식 노드가 반환하는 행을 단순히 메모리에 저장하는 역활을 하고, *Memoize* 노드는 서로 다른 매개변수 값에 대해 반환된 행을 개별적으로 캐싱하여 관리한다.
- 오버플로우가 발생하면, *Materialize*는 행을 디스크로 내보내기 시작하지만, *Memoize*는 메모리에 모든 행을 유지한다(그렇지 않으면 캐싱의 의미가 없다).


Memoize를 사용하는 쿼리의 예 : 

```sql
=> EXPLAIN SELECT * 
   FROM flights f 
   JOIN aircrafts_data a ON f.aircraft_code = a.aircraft_code 
   WHERE f.flight_no = 'PG0003';
   
QUERY PLAN
────────────────────────────────────────────────────────────────────────────
Nested Loop  (cost=5.44..387.10 rows=113 width=135)
  ->  Bitmap Heap Scan on flights f  (cost=5.30..382.22 rows=113 width=63)
        Recheck Cond: (flight_no = 'PG0003'::bpchar)
  ->  Bitmap Index Scan on flights_flight_no_scheduled_depart_idx  
        (cost=0.00..5.27 rows=113 width=0)
        Index Cond: (flight_no = 'PG0003'::bpchar)
  ->  Memoize  (cost=0.15..0.27 rows=1 width=72)
        Cache Key: f.aircraft_code
        Cache Mode: logical
  ->  Index Scan using aircrafts_pkey on aircrafts_data a  
        (cost=0.14..0.26 rows=1 width=72)
        Index Cond: (aircraft_code = f.aircraft_code)
(13 rows)
```

캐시된 행을 저장하는데 사용되는 메모리 청크의 크기는 *work_mem X hash_mem_multiplier*
이다.  두번째 파라미터 이름에서 암시되듯이, 캐시된 행들은 해시 테이블에 저장된다(open addressing) [^2]
해시키는 (계획에서 *Cache Key*로 보임) 매개변수 값이다(만약 여러개라면, 여러값이 해시키).

모든 해시 키는 리스트로 묶인다; 이 리스트의 한쪽 끝은 cold로 간주되며(오랫동안 사용되지 않은 키들을 포함) 다른쪽 끝은 hot으로 간주된다(자주 사용되는 키).

Memoize 노드에서 호출된 매개변수 값이 이미 캐시된 행들과 일치하는 경우, 이 행들은 자식 노드를 확인하지 않고 바로 부모 노드로(Nested Loop) 전달된다. 이때 사용된 해시 키는 리스트의 hot 끝으로 이동한다.

만약에 캐시에 필요한 행이 없는 경우, Memoize 노드는 자식 노드에서 이를 가져오고, 캐시하며, 부모노드로 전달한다. 이때 해시 키는 hot상태가 된다.

만약 새로운 데이터가 캐시되면서 사용 가능한 메모리가 모두 차게 되면, 공간을 확보하기 위해 cold 키에 해당하는 행들이 제거된다. 이 eviction 알고리즘은 PostgreSQL 버퍼 캐시에서 사용되는 것과는 다르지만, 목적은 동일하다.

일부 파라미터는 너무 많은 일치하는 행을 가지고 있어, 다른 모든 행이 이미 제거되었음에도 불구하고 메모리 청크에 맞지 않을 수 있다. 
이러한 파라미터는 스킵된다-일부 행만 캐시해도, 다음 호출에서 자식 노드로부터 모든 행을 가져와야되기 때문이다.


## Cost and cardinality estimations
이 계산은 앞서 본 것과 매우 유사하다. 중요한 점은 계획에서 보이는 Memoize 노드의 비용이 실제 비용과 직접적인 관련이 없다는 것이다 : 이는 단지 자식 노드의 비용에 *cpu_tuple_cost* 값을 더한 것이다. [^1]

우리는 이미 Materialize 노드에 대한 유사한 상황을 보았다 : 이 비용은 단지 후속 스캔에 대한 비용만 계산되며[^2], 그 실제 비용은 계획에 반영되지 않는다.

명백하게, Memoize 노드를 사용하는 것이 자식 노드보다 비용이 적을 때 효과가 있다. 후속 스캔 비용은  캐시 접근 프로필과 캐싱에 사용할 수 있는 메모리 청크의 크기에 따라 달라진다.
계산된 값은 주로 내부 집합에서 스캔되는 고유 매개변수 값의 수를 정확히 추정하는 것에 크게 의존한다. [^3]
이 고유값의 수를 기반으로, 캐시할 행과 evict될 행의 확률을 계산할 수 있다. hit이 예상되면 추정된 비용이 줄어들고, evict가 예상되면 비용이 증가한다. 이 계산의 자세한 내용은 생략한다.


쿼리 실행 중 실제로 어떤 일이 일어나는지 파악하기 위해, 평소처럼`EXPLAN ANALYZE`문을 사용해 보자 : 

```sql
=> EXPLAIN (analyze, costs off, timing off, summary off)
   SELECT * 
   FROM flights f
   JOIN aircrafts_data a ON f.aircraft_code = a.aircraft_code
   WHERE f.flight_no = 'PG0003';

QUERY PLAN
────────────────────────────────────────────────────────────────────────────
Nested Loop (actual rows=113 loops=1)
  -> Bitmap Heap Scan on flights f (actual rows=113 loops=1)
       Recheck Cond: (flight_no = 'PG0003'::bpchar)
       Heap Blocks: exact=2
	  -> Bitmap Index Scan on flights_flight_no_scheduled_depart_idx (actual rows=113 loops=1)
       Index Cond: (flight_no = 'PG0003'::bpchar)
  -> Memoize (actual rows=1 loops=113)
       Cache Key: f.aircraft_code
       Cache Mode: logical
       Hits: 112  Misses: 1  Evictions: 0  Overflows: 0  Memory Usage: 1kB
	  -> Index Scan using aircrafts_pkey on aircrafts_data a (actual rows=1 loops=1)
       Index Cond: (aircraft_code = f.aircraft_code)
(16 rows)
```

이 쿼리는 동일한 경로를 따르며 특정 유형의 항공기가 운항하는 flights 데이터를 선택한다. 따라서, Memoize 노드의 모든 호출에서 동일 해시 키를 사용한다.
첫 행은 테이블에서 가져와야 했다 (Misses:1), 그러나 이후의 행들은 모두 캐시에 있었다(Hits: 112).
전체 작업은 1KB의 메모리만 사용하여 처리되었다.

나머지 2개의 값(*evictions*,*overflow*)는 0이다 : 이들은 evictions의 수와, 특정 매개변수 세트와 관련된 모든 행을 캐시할 수 없었을 때 발생한 캐시 오버플로우 횟수를 나타낸다.
만약 이 값들이 크게 나타난다면 할당된 캐시 크기가 너무 작다는 것을 의미하며, 이는 매개변수 고유값 수를 부정확하게 측정했기 때문일 수 있다. 이렇게 되면, Memoize 노드를 사용하는 것이 상당히 비싸질 수 있다.
극단적인 경우에, *enable_memorize* 파라미터를 비활성화해서 플래너가 캐싱을 사용하지 못하게 할 수 있다.




[^1]:[backend/optimizer/util/pathnode.c, create_memoize_path function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/optimizer/util/pathnode.c;hb=REL_14_STABLE)

[^2]:[backend/optimizer/path/costsize.c, cost_memoize_rescan function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/optimizer/path/costsize.c;hb=REL_14_STABLE)

[^3]:[backend/utils/adt/selfuncs.c, estimate_num_groups function](backend/utils/adt/selfuncs.c, estimate_num_groups function)


[^1]:[backend/executor/nodeMemoize.c](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeMemoize.c;hb=REL_14_STABLE)

[^2]:[include/lib/simplehash.h](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/include/lib/simplehash.h;hb=REL_14_STABLE)