
모든 병렬 프로세스의 통합 메모리로도, 전체 테이블을 해시 테이블에 담기 부족할 수 있다. 이는 계획 단계에서 명확해지거나, 쿼리 실행 중에도 나타날 수 있다.
이 경우 나타나는 two-pass 알고리즘은 지금까지와는 다르다.

주요 차이점은 큰 하나의 해시 테이블 대신 여러개의 작은 해시 테이블을 생성한다는 것이다.
각 프로세스는 자신만의 테이블을 생성하고, 독립적으로 자신의 배치를 처리한다. (그러나 별도의 해시 테이블들이 여전히 공유 메모리에 위치해 있기 때문에, 모든 프로세스는 이 테이블들에 접근할 수 있다.)
만약 계획이 하나 이상의 배치가 필요하다면, [^1] 각 프로세스에 대해 별도의 해시 테이블이 즉시 생성된다. 만약 실행 단계에서 이러한 결정이 내려지면, 해시 테이블이 다시 생성된다. [^2]

따라서, 첫 단계에서 프로세스들은 내부 집합을 병렬로 스캔하고, 이를 여러 배치로 나누어 임시 파일에 기록한다. [^3] 각 프로세스는 자신에게 할당된 내부 집합의 일부만 읽기 때문에, 어느 프로세스도 배치에 대해 완전한 해시 테이블을 생성하지 않는다(첫 번째도 마찬가지).
각 배치의 모든 행은 동기화된 방식으로 병렬 프로세스가 작성한 파일에만 축척된다. [^4] 따라서 non-parallel이거나 one-pass parallel 병렬 버전과 달리, two-pass hash join은 첫 번째 배치를 포함하여 모든 배치를 디스크에 기록한다.

![400](image/Pasted%20image%2020241024100433.png)
모든 프로세스가 내부 집합의 해싱을 완료하면, 2단계가 시작된다. [^5]

non-parallel 알고리즘이 사용되었다면, 첫 번째 배치에 속하는 외부 집합의 행들은 즉시 해시 테이블과 매칭되었을 것이다. 그러나 병렬 버전에서는, 메모리가 아직 해시 테이블을 가지고 있지 않으므로, 작업자들은 배치를 독립적으로 처리한다.
따라서, 두 번째 단계는 외부 집합을 병렬로 스캔하여 행들을 배치로 나누고, 각 배치는 별도의 임시 파일에 기록하는 것으로 시작한다. [^6]
스캔된 행들은 해시 테이블에 삽입되지 않으며(첫 단계처럼), 배치의 수는 절대 증가하지 않는다.

모든 프로세스가 외부 집합의 스캔을 완료하면, 디스크에 2N개의 임시 파일이 생성된다. 이들은 내부/외부 집합의 배치들이다.

![400](image/Pasted%20image%2020241024101100.png)


그 후 각 프로세스는 하나의 배치를 선택하여 조인을 수행한다 : 내부 집합의 행들을 메모리의 해시 테이블에 로드한 다음, 외부 집합의  행들을 스캔하여 해시 테이블과 비교한다.
배치 조인이 완료되면, 프로세스는 아직 처리되지 않은 다음 배치를 선택하여 같은 작업을 반복한다. [^7]

![400](image/Pasted%20image%2020241024101418.png)
모든 배치가 처리됬다면, 자신의 배치를 완료한 프로세스는 다른 프로세스가 현재 처리 중인 배치 중 하나를 처리하기 시작한다. 이러한 동시 처리가 가능한 이유는 모든 해시 테이블이 공유 메모리에 있기 때문이다.

![200](image/Pasted%20image%2020241024101559.png)
이 접근 방식은 하나의 큰 해시 테이블을 사용하는 것보다 더 효율적이다 : 병렬 처리를 설정하는 것이 더 쉽고, 동기화 비용이 더 적기 때문이다.



[^1]:[backend/executor/nodeHash.c, ExecChooseHashTableSize function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)
[^2]:[backend/executor/nodeHash.c, ExecParallelHashIncreaseNumBatches function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)
[^3]:[backend/executor/nodeHash.c, MultiExecParallelHash function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)
[^4]:[backend/utils/sort/sharedtuplestore.c](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/utils/sort/sharedtuplestore.c;hb=REL_14_STABLE)
[^5]:[ backend/executor/nodeHashjoin.c, ExecParallelHashJoin function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHashjoin.c;hb=REL_14_STABLE)
[^6]:[ backend/executor/nodeHashjoin.c, ExecParallelHashJoinPartitionOuter function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHashjoin.c;hb=REL_14_STABLE)

[^7]:[ backend/executor/nodeHashjoin.c, ExecParallelHashJoinNewBatch function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHashjoin.c;hb=REL_14_STABLE)