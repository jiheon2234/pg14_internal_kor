플래너가 해시 테이블이 할당된 메모리에 맞지 않을 것으로 추정한 경우, 내부 집합의 행들이 배체로 나뉘어 개별적으로 처리된다.
배치의 수(버킷의 수와 마찬가지로)는 항상 2의 제곱이다 ; 사용할 배치는 해시 키의 비트 수에 따라 결정된다. [^1]

두 일치하는 행은 항상 같은 배치에 속한다. 다른 배치에 속한 행들은 동일한 해시 코드를 가질 수 없다.

모든 배치는 동일한 수의 해시 키를 보유한다. 만약 데이터가 균등하게 분포되어 있다면,  배치 크기는 항상 (거의)같을 것이다. 플래너는 적절한 배치 수를 선택함으로서 메모리 소비를 제어할 수 있다. [^2]

첫 단계에서, 실행기는 내부 집합의 행들을 스캔하여 해시 테이블을 만든다.
스캔된 행이 첫 배치에 속하면, 해시 테이블에 추가되고 RAM에 저장된다.
그렇지 않으면, 임시 파일(각 배치마다 별도의)에 기록된다. [^3]

> 세션이 디스크에 의해 저장할 수 있는 임시 파일의 총 용량은 *temp_file_limit* 파라미터에 의해 제한된다(임시 테이블은 이 제한에 포함되지 않는다). 세션이 이 값을 초과하면, 쿼리는 중단된다.

![400](image/Pasted%20image%2020241023162746.png)

두 번째 단계에서, 외부 집합이 스캔된다. 만약 행이 첫 배치에 속하면, 내부 집합의 첫 번째 배치  행들을 포함한 해시 테이블과 비교한다(다른 배치와 일치하는 행은 있을 수 없다).

만약 행이 다른 배치에 속하면, 그 행은 임시 파일에 저장된다. 이는 각 배치마다 따로 생성된다.
따라서, N개의 배치는 $2(N-1)$ 개의 파일을 사용할 수 있다(일부 배치가 비었다면 더 적을수 있다).

두번째 단계가 완료되면, 해시 테이블에 할당된 메모리는 해제된다.
이 시점에서, 첫 배치의 조인 결과를 얻은 상태이다.

![400](image/Pasted%20image%2020241023163338.png)

두 단계는 디스크에 저장된 각 배치에 대해 반복된다 :  내부 집합의 행들은 임시 파일에서 해시 테이블로 전송되고; 같은 배치에 속하는 외부 집합의 행들은 또 다른 임시 파일에서  읽어들여 이 해시 테이블과 비교한다. 처리가 완료되면, 임시 파일들은 삭제된다.


![400](image/Pasted%20image%2020241023163749.png)

단일 패스 조인과 달리, 2단계 해시 조인에 대한 `EXPLAIN` 명령어의 결과는 여러 배치를 포함한다. 만약 `BUFFERS` 옵션과 함께 실행되면, 이 명령어는 디스크 접근의 통계도 표시된다.

```sql
EXPLAIN (analyze, buffers, costs off, timing off, summary off)
SELECT *
FROM bookings b
JOIN tickets t ON b.book_ref = t.book_ref;
QUERY PLAN
────────────────────────────────────────────────────────────────────────────
Hash Join (actual rows=2949857 loops=1)
  Hash Cond: (t.book_ref = b.book_ref)
  Buffers: shared hit=7236 read=55626, temp read=55126 written=55126
  -> Seq Scan on tickets t (actual rows=2949857 loops=1)
     Buffers: shared read=49415
  -> Hash (actual rows=2111110 loops=1)
     Buckets: 65536  Batches: 64  Memory Usage: 2277kB
     Buffers: shared hit=7236 read=6211, temp written=10858
	  -> Seq Scan on bookings b (actual rows=2111110 loops=1)
	     Buffers: shared hit=7236 read=6211
(11 rows)
```

이미 위에서 *work_mem*세팅을 증가시킨 이 쿼리를 보았다. 기본값인 4MB는 전체 해시 테이블을 메모리에 적재하기는 너무 작다; 이 예시에서, 데이터는 64개의 배치로 쪼개지며, 해시테이블은 $2^{16}$ 개의 버킷을 사용한다.
해시 테이블이 구축될 때 *(Hash Node)*, 데이터는 임시 파일에 쓰여지고 *(temp written)*; 조인 단계에서는 *(Hash Join node)* 임시 파일들이 읽히고 쓰여진다 (*temp read, written*).

임시 파일에 대한 더 많은 통계를 수집하려면, *log_temp_files* 파라미터를 0으로 설정할 수 있다. 그러면 서버 로그에 모든 임시 파일과 해당 크기가 나열된다(삭제 시점의 크기 기준).

[^1]:[backend/executor/nodeHash.c, ExecHashGetBucketAndBatch function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)

[^2]:[backend/executor/nodeHash.c, ExecChooseHashTableSize function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)

[^3]:[backend/executor/nodeHash.c, ExecHashTableInsert function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/executor/nodeHash.c;hb=REL_14_STABLE)