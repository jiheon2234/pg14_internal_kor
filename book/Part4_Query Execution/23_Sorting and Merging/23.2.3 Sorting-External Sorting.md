스캔을 통해 데이터가 메모리에서 정렬하기에 너무 크다는 것이 확인되면, sorting 노드는 external merge sorting (계획에서는 *external merge*)로 전환된다.

이미 스캔된 행은 qicksort로 메모리에서 정렬되며 임시 파일로 기록된다.

![400](_static/Pasted%20image%2020241025105105.png)


그 후, 후속 행들이 해제된 메모리로 읽혀지며, 이 절차는 모든 데이터가 미리 정렬된 파일에 기록될 때까지 반복된다.

![400](_static/Pasted%20image%2020241025105250.png)

다음으로, 이 파일들은 하나로 병합된다. 이 작업은 대략적으로 머지 조인에 사용되는 알고리즘과 동일한 알고리즘에 의해 수행된다; 주요 차이점은 한 번에 두 개 이상의 파일을 처리할 수 있다는 점이다.

머지 연산은 메모리를 많이 쓰지 않는다. 사실, 파일당 한 행을 담을 공간만 있으면 충분하다.
각 파일에서 첫 행이 읽혀지며, 가장 낮은 값이 부분 결과로 반환되고, 해제된 메모리는 동일한 파일에서 가져온 다음 행으로 채워진다.

실제로는 행이 하나씩이 아닌 32페이지 단위로 읽어지며, 이는 I/O횟수를 줄여준다.
한번의 반복에서 머지되는 파일의 수는 사용 가능한 메모리에 따라 다르지만, 최소 6개 이상이다. 상한선은 500으로 제한되는데, 파일이 너무 많으면 효율성이 떨어지기 때문이다. [^1]

>정렬 알고리즘은 오래된 용어를 가지고 있다. External sorting은 원래 자기 테이프를 사용하여 수행되었고, PostgreSQL은 임시 파일을 제어하는 구성 요소에 대해 비슷한  이름을 유지하고 있다. [^2] 부분적으로 정렬된 데이터 집합을 "runs"라고 부르며, 머지에 참여하는 runs의 수를 "merge order"라고 부른다. 나는 이 용어를 사용하지 않았지만, PostgreSQL의 코드와 주석을 이해하고 싶다면 참고하자.

정렬된 임시 파일들이 한번에 머지될 수 없다면, 여러 반복을 통해서 처리되어야 하며, 부분 결과는 새로운 임시 파일에 기록된다.
각 반복은 읽고 써야 하는 데이터의 양을 증가시키므로, 더 많은 메모리가 사용 가능할수록 외부 정렬이 더 빠르게 완료된다.

![500](_static/Pasted%20image%2020241025110228.png)

다음 반복에서는 새로 생성된 임시 파일들을 병합한다.

![250](_static/Pasted%20image%2020241025110314.png)

최종 병합은 일반적으로 지연되며, 상위 노드가 데이터를 가져올 때 즉시 수행된다.

`EXPLAIN ANALYZE` 명령을 실행하여 외부 정렬에 의해 얼마나 많은 디스크 공간이 사용되었는지 확인해 보자. `BUFFERS` 옵션은 임시 파일의 버퍼 사용 통계를 표시한다(r/w). 쓰인 버퍼의 수는 읽힌 버퍼의 수와 거의 비슷하며, 킬로바이트로 변환된 값은 계획에서 *Disk*로 표시된다 : 

```sql
=> EXPLAIN (analyze, buffers, costs off, timing off, summary off)
   SELECT * FROM flights
   ORDER BY scheduled_departure;

QUERY PLAN
--------------------------------------------------------------
Sort (actual rows=214867 loops=1)
Sort Key: scheduled_departure
Sort Method: external merge
Disk: 17136kB
Buffers: shared hit=2627, temp read=2142 written=2150
-> Seq Scan on flights (actual rows=214867 loops=1)
Buffers: shared hit=2624
(6 rows)
```

임시 파일 사용에 대한 더 많은 세부 정보를 서버 로그에 출력하려면, *log_temp_files* 파라미터를 활성화할 수 있다.

## Cost estimation
외부 정렬이 포함된 실행 계획을 예로 들어 보자 : 
```sql
=> EXPLAIN SELECT *
   FROM flights
   ORDER BY scheduled_departure;

QUERY PLAN
------------------------------------------------------------
Sort
  (cost=31883.96..32421.12 rows=214867 width=63)
  Sort Key: scheduled_departure
-> Seq Scan on flights
  (cost=0.00..4772.67 rows=214867 width=63)
(3 rows)

```
여기서 비교의 일반적인 비용(비교 횟수는 메모리에서하는 qicksort와 같다)는 I/O 비용에 의해 확장된다. [^3]
모든 입력 데이터는 먼저 디스크의 임시 파일에 기록된 후, 머지 작업 중에 디스크에서 다시 읽어야 한다(생성된 모든 파일을 한 번의 반복에서 머지할 수 없는 경우엔 여러번 읽혀질 수 있다).

디스크 작업의 $3/4$(읽기 쓰기 둘다)는 순차적이고, $1/4$는 랜덤으로 이루어진다고 가정한다.
디스크에 기록되는 데이터의 양은 정렬할 행의 수와 쿼리에서 사용된 열의 수에 따라 달라진다.[^4] 이 예시에서, 쿼리는 *flights*테이블의 모든 열을 표시하므로, 디스크에 쏟아지는 데이터의 크기는 튜플과 페이지 메타데이터를 고려하지 않으면 테이블 전체 크기와 거의 동일하다(2624 대신 2309페이지).

여기서 정렬은 한번의 반복에서 완료된다.
따라서, 이 실행 계획에서 정렬 비용은 다음과 같다 : 

```sql
=> WITH costs(startup) AS (
   SELECT 4772.67 + round((
   current_setting('cpu_operator_cost')::real * 2 *
   214867 * log(2, 214867) +
   (current_setting('seq_page_cost')::real * 0.75 +
   current_setting('random_page_cost')::real * 0.25) *
   2 * 2309 * 1 -- 한 번의 반복
   ))::numeric, 2)
   SELECT startup,
   startup + round((
   current_setting('cpu_operator_cost')::real * 214867
   )::numeric, 2) AS total
   FROM costs;

 startup  |   total  
----------+-----------
 31883.96 | 32421.13
(1 row)
```



[^1]:[backend/utils/sort/tuplesort.c, tuplesort_merge_order function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/utils/sort/tuplesort.c;hb=REL_14_STABLE)

[^2]:[ backend/utils/sort/logtape.c](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/utils/sort/logtape.c;hb=REL_14_STABLE)

[^3]:[backend/optimizer/path/costsize.c, cost_sort function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/optimizer/path/costsize.c;hb=REL_14_STABLE)
[^4]:[backend/optimizer/path/costsize.c, relation_byte_size function](https://git.postgresql.org/gitweb/?p=postgresql.git;a=blob;f=src/backend/optimizer/path/costsize.c;hb=REL_14_STABLE)